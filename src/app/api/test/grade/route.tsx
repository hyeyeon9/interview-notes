import { NextResponse } from "next/server";
import OpenAI from "openai";

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY!,
});

type QAItem = {
  question: string;
  answers: string;
};

export async function POST(req: Request) {
  const { payload } = await req.json();

  const prompt = payload
    .map(
      (item: QAItem, index: number) => `
Q${index + 1}. ${item.question}
A${index + 1}. ${item.answers || "(ë¯¸ì‘ì„±)"}
`
    )
    .join("\n");

  const fullPrompt = `
ë‹¤ìŒì€ ëª¨ì˜ ë©´ì ‘ ì§ˆë¬¸ê³¼ ë‹µë³€ ëª©ë¡ì…ë‹ˆë‹¤.

1. ê° ì§ˆë¬¸ì— ëŒ€í•´ 100ì  ë§Œì  ê¸°ì¤€ìœ¼ë¡œ ì ìˆ˜ë§Œ ë¶€ì—¬í•´ì£¼ì„¸ìš”.
   - í˜•ì‹: **Q1. ì§ˆë¬¸ ë‚´ìš©** â†’ ì ìˆ˜: (ìˆ«ì)

2. ì´ì–´ì„œ ì¢…í•© í‰ê°€ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”. ì•„ë˜ í˜•ì‹ì„ ì§€ì¼œ ì£¼ì„¸ìš”:
---
**ğŸŸ¢ ì˜í•œ ì **
- ì˜ˆì‹œì²˜ëŸ¼ ê¸€ë¨¸ë¦¬í‘œë¡œ 2~3ê°€ì§€ ì‘ì„±

**ğŸ”´ ê°œì„ í•  ì **
- ì˜ˆì‹œì²˜ëŸ¼ ê¸€ë¨¸ë¦¬í‘œë¡œ 2~3ê°€ì§€ ì‘ì„±

**ğŸ“ ì¢…í•© í‰ê°€**
- 2~3ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½ëœ ì „ì²´ ì´í‰

---
${prompt}
`;

  const completion = await openai.chat.completions.create({
    model: "gpt-4o",
    messages: [{ role: "user", content: fullPrompt }],
    temperature: 0.7,
  });

  const result = completion.choices[0].message.content;

  return NextResponse.json({ result });
}
